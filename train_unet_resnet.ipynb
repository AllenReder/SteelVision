{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from model.unet import UNet\n",
    "from model.unet_resnet import UNetResNet\n",
    "from model.unet_inception import UNetInception\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import SteelDataset\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display as ipythondisplay\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory:\n",
    "    def __init__(self, smoothing_factor=0.0):\n",
    "        self.alpha = smoothing_factor\n",
    "        self.loss = []\n",
    "\n",
    "    def append(self, value):\n",
    "        self.loss.append(\n",
    "            self.alpha*self.loss[-1] + (1-self.alpha)*value if len(self.loss) > 0 else value)\n",
    "\n",
    "    def get(self):\n",
    "        return self.loss\n",
    "\n",
    "\n",
    "class PeriodicPlotter:\n",
    "    def __init__(self, sec, xlabel='', ylabel='', scale=None):\n",
    "\n",
    "        self.xlabel = xlabel\n",
    "        self.ylabel = ylabel\n",
    "        self.sec = sec\n",
    "        self.scale = scale\n",
    "\n",
    "        self.tic = time.time()\n",
    "\n",
    "    def plot(self, data, name):\n",
    "        if time.time() - self.tic > self.sec:\n",
    "            plt.cla()\n",
    "\n",
    "            if not isinstance(data, list):\n",
    "                data = [data]\n",
    "\n",
    "            if not isinstance(name, list):\n",
    "                name = [name]\n",
    "\n",
    "            for d, n in zip(data, name):  # 为每个数据标注对应的标签名\n",
    "                if self.scale is None:\n",
    "                    plt.plot(d, label=n)  # 添加标签\n",
    "                elif self.scale == 'semilogx':\n",
    "                    plt.semilogx(d, label=n)  # 添加标签\n",
    "                elif self.scale == 'semilogy':\n",
    "                    plt.semilogy(d, label=n)  # 添加标签\n",
    "                elif self.scale == 'loglog':\n",
    "                    plt.loglog(d, label=n)  # 添加标签\n",
    "                else:\n",
    "                    raise ValueError(\n",
    "                        \"unrecognized parameter scale {}\".format(self.scale))\n",
    "\n",
    "            plt.xlabel(self.xlabel)\n",
    "            plt.ylabel(self.ylabel)\n",
    "            plt.legend()  # 显示图例\n",
    "            ipythondisplay.clear_output(wait=True)\n",
    "            ipythondisplay.display(plt.gcf())\n",
    "\n",
    "            self.tic = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置路径\n",
    "train_images_path = './data/images/all'\n",
    "train_masks_path = './data/annotations/all'\n",
    "train_image_files = sorted([os.path.join(train_images_path, f) for f in os.listdir(\n",
    "    train_images_path) if f.endswith(('.png', '.jpg'))])\n",
    "train_mask_files = sorted([os.path.join(train_masks_path, f) for f in os.listdir(\n",
    "    train_masks_path) if f.endswith(('.png', '.jpg'))])\n",
    "\n",
    "# 数据集和数据加载器\n",
    "bs = 8\n",
    "train_dataset = SteelDataset(train_image_files, train_mask_files, eval=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\.conda\\envs\\gpu\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrator\\.conda\\envs\\gpu\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型参数量: 34.66M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:   9%|▊         | 45/522 [00:08<01:27,  5.42it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 51\u001b[0m\n\u001b[0;32m     48\u001b[0m union \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m1\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m: \u001b[38;5;241m0\u001b[39m}\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# 训练循环\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, masks \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     52\u001b[0m     images, masks \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), masks\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;66;03m# 前向传播\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\.conda\\envs\\gpu\\lib\\site-packages\\tqdm\\std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1185\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\.conda\\envs\\gpu\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\.conda\\envs\\gpu\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\.conda\\envs\\gpu\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\.conda\\envs\\gpu\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32md:\\Program\\AI\\SteelVision\\dataset.py:31\u001b[0m, in \u001b[0;36mSteelDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m---> 31\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_paths\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIMREAD_GRAYSCALE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m     mask \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_paths[idx], cv2\u001b[38;5;241m.\u001b[39mIMREAD_GRAYSCALE)\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m image \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# 模型加载并发送至设备\n",
    "model = UNetResNet().to(device)\n",
    "\n",
    "# 输出模型参数量大小\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"模型参数量: {total_params / 1e6:.2f}M\")\n",
    "\n",
    "# 优化器和学习率调度器\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=5, eta_min=1e-6)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# 冻结 ResNet 编码器部分参数\n",
    "for param in model.encoder0.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.encoder1.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.encoder2.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.encoder3.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.encoder4.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 初始化一些工具，用于绘图和记录历史\n",
    "plotter = PeriodicPlotter(sec=2, xlabel='Iterations', ylabel='')\n",
    "loss_history = LossHistory()\n",
    "iou_history = [None, LossHistory(), LossHistory(), LossHistory()]\n",
    "miou_history = LossHistory()\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    # 在第10个epoch解冻 encoder3 部分\n",
    "    if epoch == 10:\n",
    "        for param in model.encoder3.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    # 在第20个epoch解冻 encoder4 部分\n",
    "    if epoch == 20:\n",
    "        for param in model.encoder4.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    running_loss = 0.0\n",
    "    inter = {1: 0, 2: 0, 3: 0}\n",
    "    union = {1: 0, 2: 0, 3: 0}\n",
    "\n",
    "    # 训练循环\n",
    "    for images, masks in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "        # 前向传播\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "\n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # 计算 IoU\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        for i in range(images.size(0)):  # 遍历批次中的每张图像\n",
    "            for j in range(1, 4):  # 分类标签 1, 2, 3\n",
    "                inter[j] += ((preds[i] == j) & (masks[i] == j)).sum().item()\n",
    "                union[j] += ((preds[i] == j) | (masks[i] == j)).sum().item()\n",
    "\n",
    "    # 更新学习率调度器\n",
    "    if epoch > 20:\n",
    "        scheduler.step()\n",
    "\n",
    "    # 计算并存储 IoU 和 mIoU\n",
    "    for j in range(1, 4):\n",
    "        iou = inter[j] / union[j] if union[j] > 0 else 0\n",
    "        iou_history[j].append(iou)\n",
    "    miou = sum(iou_history[j].get()[-1] for j in range(1, 4)) / 3\n",
    "    miou_history.append(miou)\n",
    "\n",
    "    # 存储损失\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    loss_history.append(avg_loss)\n",
    "\n",
    "    # 绘制当前epoch的损失和IoU\n",
    "    plotter.plot([loss_history.get(), iou_history[1].get(), iou_history[2].get(), iou_history[3].get(), miou_history.get()],\n",
    "                 name=['loss', 'IoU_1', 'IoU_2', 'IoU_3', 'mIoU'])\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, mIoU: {miou:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'./saved_model/unet_inception_epoch_50.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
