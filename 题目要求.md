# 一、赛题背景
钢材表面缺陷检测是钢铁行业中至关重要的一环。随着工业化进程的不断推进，对钢材质量的要求越来越高，其中表面缺陷是保证钢材质量的重要手段之一。传统的人工检测方式存在着效率低、准确率不高等问题，且难以满足大规模生产的需求。因此，基于深度学习的钢材表面缺陷检测方法成为行业的研究热点。

基于深度学习的钢材表面缺陷检测实际应用场景主要包括工业生产线上的自动检测、智能化仓储与物流、生产数据分析与预测维护等。目前，钢材表面缺陷检测所面临的主要难题有复杂多样的缺陷类型：钢材表面可能存在各种不同类型的缺陷，如划伤、生锈、夹杂物等，这些缺陷形态复杂，使得检测算法需要具有较强的泛化能力。图像质量和现场环境条件不一：钢材表面的图像可能受到光照、角度等因素的影响，导致图像质量参差不齐，这给算法的稳定性和鲁棒性带来挑战。大规模生产需求：钢铁行业通常需要大规模生产，因此对于缺陷检测算法的实时性和高效性要求较高。

因此进行钢材表面缺陷检测与分割的研究可以解决工业生产中的诸多痛点，提高生产效率并提升生产质量。



# 二、赛题任务
本赛题旨在利用深度学习技术实现钢材表面缺陷的分割识别，即对给定的钢材图像中的缺陷部分进行像素级别的分割检测。

## 1. 任务描述

在钢材表面缺陷检测中，我们需要使用深度学习算法对这些图像进行分析和处理，从而检测出可能存在的缺陷，并对检测出的缺陷进行精确的分割，这一步骤通常使用深度学习中的语义分割。

## 2. 任务说明

①数据集：主办方提供钢材表面缺陷检测数据集。

②设计模型：参赛者设计基于深度学习的缺陷检测算法，实现对钢材表面缺陷的高效检测与分割。要求所设计的模型参数量要求在50M以内 (不包括50M)。

③缺陷分割：参赛者所提交的模型能够准确地将钢材表面图像中的缺陷部分进行像素级别的分割标注，以实现精确的缺陷识别。

## 3.任务输入输出说明

数据集Ground Truth缺陷标签说明：背景灰度值：0；三类缺陷灰度值分别为：1，2，3；

输出钢材表面图像缺陷的检测结果: 采用Class IoU、mIoU 和FPS为评价指标，其中，Class IoU与mIoU：整个测试集输出结果与相应Ground Truth类缺陷交并比、平均交并比。FPS：模型每秒可以处理完成图像帧数。



# 三、数据集
包括若干张训练图像和若干张测试图像，涵盖三种不同的缺陷类别：夹杂物 (Inclusions)、补丁(Patches)和划痕(Scratches)，以及不同类别的混合缺陷。(报名成功后，通知公告中获取数据集链接及提取码)。



# 四、解题思路
1.数据集处理：理解数据集中的图像和标签，找到对应标签处理的方法。

2.模型设计：结合目前基于深度学习的表面缺陷检测方法，并根据钢材表面缺陷数据的特点，处理数据设计相应的模型。

3.可视化及数据结果分析：基于可视化及指标数据分析，论证所设计方法或模型的优势。



# 五、评价方式
1.数据指标评价方式：评估以UNet为基准模型，需在同一环境运行UNet模型与自建模型；最终需要提交以上对应两个模型的Class IoU、mIoU 、FPS和模型参数量，共计12个指标结果。

2.总决赛综合评价方式参考大赛组委会评审总则。



# 六、成绩提交
以“参赛队伍名称_提交日期”为名的文件夹， 参赛者需提交一个以“参赛队伍名称+提交日期（YYYYMMDD）”命名的文件压缩包（压缩包格式规定.7z，压缩包不要在根目录嵌套一层队名文件夹）（例如：江南大师队20240906.7z），队伍名称与报名时填写的队名保持一致，开头无需添加学校名称， 提交材料清单如下：

1.文件夹1- baseline_predictions：UNet在每张测试图像上的分割结果，以.npy的形式保存。

2.文件夹2- test_ground_truths：每张测试图像的GT分割结果，以.npy的形式保存。

3.文件夹3- test_predictions：选手所用模型在每张测试图像上的分割结果，以.npy的形式保存。

4.文件1- model.pth：使用 torch.save(model.state_dict(), 'model.pth')代码保存模型。

5.文件2- model.py：自建网络模型代码文件。特别提醒，为平台自动计分需要，自建网络名称须统一命名为self_net。另外，尽量引入标准模块，如torchvision，否则，服务器上找不到其他第三方模块，容易出错！

6.文件3- 算法描述文档：pdf格式，包含模型的主要框图、算法描述、详细阐述思路、使用的数据处理技术及模型架构，主要创新点说明。并请注明所采用的python版本与环境所需软件包。

7.文件4– 关键指标数据文档：txt格式，以字典形式存放，按顺序依次为UNet模型的Class1 IoU、Class2 IoU、Class3 IoU、mIoU 、FPS 、模型参数量，以及自己模型的Class1 IoU、Class2 IoU、Class3 IoU、mIoU 、FPS 和模型参数量共计12个指标结果。

参考格式如下：

results = { "UNet": {

"Class1_IoU": 0.71,

"Class2_IoU": 0.72,

"Class3_IoU": 0.73,

"mIoU": 0.72,

"FPS": 25,

"Parameters": 10    },

"OursModel": {

"Class1_IoU": 0.74,

"Class2_IoU": 0.75,

"Class3_IoU": 0.76,

"mIoU": 0.75,

"FPS": 30,

"Parameters": 15  }}



注：

1. 选手需要严格按照以上方式命名这3个文件夹和4个文件。文件夹中分割结果的文件名应跟随对应的测试图像，比如测试文件是000001.jpg，则baseline_predictions和test_predictions中对应的分割结果都为prediction_000001.npy，test_ground_truths中对应的GT结果为ground_truth_000001.npy。

2. 经典UNet网络作为baseline（可参照使用文献1提供的相关代码），超参数自行进行调整设定。结合当前可参考的研究文献情况和比赛公平性的实际需要，UNet在NEU-Seg数据集上综合三类缺陷检测分割的mIoU参考值需为不低于0.75。

3. 自建网络self_net可以self_net()格式调用。

4. 如果提交的代码中含有__init__.py文件，请将此文件置为空。



# 七、参考文献
1.Ronneberger O, Fischer P, Brox T. U-net: Convolutional networks for biomedical image segmentation[C]//Medical image computing and computer-assisted intervention–MICCAI 2015: 18th international conference, Munich, Germany, October 5-9, 2015, proceedings, part III 18. Springer International Publishing, 2015: 234-241.

2.Dong H, Song K, He Y, et al. PGA-Net: Pyramid feature fusion and global context attention network for automated surface defect detection[J]. IEEE Transactions on Industrial Informatics, 2019, 16(12): 7448-7458.

3.Zhang J, Ding R, Ban M, et al. Fdsnet: An accurate real-time surface defect segmentation network[C]//ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2022: 3803-3807.